# AI Inferencing Services Hands-on Lab

## Overview

This hands-on lab provides a comprehensive walkthrough of AI model deployment, integration, and benchmarking. Through a series of guided exercises, participants will gain practical experience with various aspects of AI inferencing services, from model deployment to performance evaluation.

## Prerequisites

* Access to JupyterLab environment
* Basic understanding of Python programming
* Familiarity with AI/ML concepts

## Lab Structure

This lab consists of 7 steps, with an estimated total duration of 60 minutes.

### Steps 3-4: JupyterLab and API Integration (20 minutes)

In this section, you will:

* Work with the OpenAI package in JupyterLab
* Explore various AI frameworks and tools:
  * LlamaIndex
  * LangChain
  * CrewAI (via LiteLLM)
* Learn about embedding models and their applications
* Understand reranking model capabilities
* Practice API integration for model usage

### Step 4: Copilot Integration (8 minutes)

* Learn to integrate Copilot with CAII models
* Understand common integration challenges and their solutions
* Explore best practices for model recognition

### Step 5: Vision Language Model Use Case (5 minutes)

* Deploy and work with Vision Language Models
* Understand endpoint configuration and switching
* Practical applications of VLM in real-world scenarios

### Step 6: Traditional Model Performance Comparison (5 minutes)

* Compare performance metrics across different model types
* Understand key performance indicators
* Analyze trade-offs between different approaches

### Step 7: LLM Benchmarking (5 minutes)

* Learn about LLM evaluation methodologies
* Understand key benchmarking metrics
* Practice performance measurement and analysis

## Getting Started

1. Clone this repository:
   ```bash
   git clone https://github.com/odog96/ai-inferencing-services-hol.git
   cd ai-inferencing-services-hol