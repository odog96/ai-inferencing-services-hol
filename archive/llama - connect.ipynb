{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295cacb5-b676-4925-8677-e2a177047fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must run on => Python 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715f17e3-fef9-461e-b4a2-d0af5631b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import httpx\n",
    "import json\n",
    "from typing import List, Dict, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a58fd3-4976-41b3-af57-e50ed3da80ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35d30e1a-fad2-4a45-971f-329d133a4f19",
   "metadata": {},
   "source": [
    "**Enter url below**\n",
    "Important: when you copy model url, trim everyting after '/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa6acc2-9ae3-4b0f-b4d6-7b19d8d6659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_BASE_URL\"]\n",
    "base_url = \"https://ai-inference.ainf-cdp.vayb-xokg.cloudera.site/namespaces/serving-default/endpoints/test-model-llama-8b-v2/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ababe-6268-433f-9656-3c30e551cf38",
   "metadata": {},
   "source": [
    "**Enter Model name here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aaedd8e-52bf-4bea-8f62-208ee3e65a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta/llama-3.1-8b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e226feb-d60f-436d-ae9c-aaf460df8c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJqa3UiOiJodHRwczovL2FpbmYtYXctZGwtbWFzdGVyMC5haW5mLWNkcC52YXliLXhva2cuY2xvdWRlcmEuc2l0ZTo4NDQzL2FpbmYtYXctZGwva3Qta2VyYmVyb3Mva25veHRva2VuL2FwaS92MS9qd2tzLmpzb24iLCJraWQiOiJhbnB3NFN0QkZsTG1tZWN0RU05Z2hOVHBTZ09GdjhuN1RyRExwR3MwVEZBIiwiYWxnIjoiUlMyNTYifQ.eyJzdWIiOiJvemFyYXRlIiwiamt1IjoiaHR0cHM6Ly9haW5mLWF3LWRsLW1hc3RlcjAuYWluZi1jZHAudmF5Yi14b2tnLmNsb3VkZXJhLnNpdGU6ODQ0My9haW5mLWF3LWRsL2t0LWtlcmJlcm9zL2tub3h0b2tlbi9hcGkvdjEvandrcy5qc29uIiwia2lkIjoiYW5wdzRTdEJGbExtbWVjdEVNOWdoTlRwU2dPRnY4bjdUckRMcEdzMFRGQSIsImlzcyI6IktOT1hTU08iLCJleHAiOjE3Mzk3NjMyNTIsIm1hbmFnZWQudG9rZW4iOiJmYWxzZSIsImtub3guaWQiOiIzMmZiZDNmMy00MTA1LTQwMWYtOTY1Yi02MWI5ZGI0MTVlN2YifQ.ap7bfof3pkutwetExOQa8TP2PRWWjjHg6f-MtES_5bAg8VB-AJU160x3x-D_GmPbO7346RdZHNxNiS6p8G_fn2x33uMmt7wJQlig2bqX_Ji_AdWq6lg2d5FQz3Qq_sQHwIHWwppvSbP8zElk9m4VK2gXertcUWid-Ezl-XMYSnr4gZET_wha89YxQvr3_S7_glI4lNmECGaBkwcfWDqytOiaqkmAqRkbPxWCUE4P6c4h8GL3-MD9lPMFENVO8r_i2Ug1SL0LTzja25UnLVyiQcz5LXQVmZOjJGzD_zNLpGaetvd-Y75SckbvcnRusFte_B2hsKPRTA-1AnmV1_fl0A'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open(\"/tmp/jwt\"))[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa52d379-0f54-4c23-b6d5-091c1b31116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatClient:\n",
    "    def __init__(self, model_name: str,base_url: str):\n",
    "          \n",
    "        # Set up HTTP client\n",
    "        if \"CUSTOM_CA_STORE\" not in os.environ:\n",
    "            http_client = httpx.Client()\n",
    "        else:\n",
    "            http_client = httpx.Client(verify=os.environ[\"CUSTOM_CA_STORE\"])\n",
    "            \n",
    "        # Load API key\n",
    "        OPENAI_API_KEY = json.load(open(\"/tmp/jwt\"))[\"access_token\"]\n",
    "        \n",
    "        # Initialize OpenAI client\n",
    "        self.client = OpenAI(\n",
    "            base_url= base_url,\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            http_client=http_client,\n",
    "        )\n",
    "        \n",
    "        self.conversation_history: List[Dict[str, str]] = []\n",
    "        \n",
    "    def chat(self, message: str, stream: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Send a message to the chat model and get the response.\n",
    "        \n",
    "        Args:\n",
    "            message: The message to send to the model\n",
    "            stream: Whether to stream the response or return it all at once\n",
    "            \n",
    "        Returns:\n",
    "            The complete response as a string\n",
    "        \"\"\"\n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        if stream:\n",
    "            partial_message = \"\"\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=self.conversation_history,\n",
    "                stream=True,\n",
    "            )\n",
    "            \n",
    "            for chunk in response:\n",
    "                if chunk.choices[0].delta.content is not None:\n",
    "                    content = chunk.choices[0].delta.content\n",
    "                    partial_message += content\n",
    "                    print(content, end='', flush=True)\n",
    "            \n",
    "            print()  # New line after response is complete\n",
    "            # Add complete response to history\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": partial_message})\n",
    "            return partial_message\n",
    "            \n",
    "        else:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=self.conversation_history,\n",
    "                stream=False,\n",
    "            )\n",
    "            complete_response = response.choices[0].message.content\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": complete_response})\n",
    "            return complete_response\n",
    "    \n",
    "    def get_history(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Get the conversation history.\"\"\"\n",
    "        return self.conversation_history\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        self.conversation_history = [] = \"https://api.openai.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6603b52-e28c-4ea1-ac41-d41f11a9f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chat client\n",
    "chat_client = ChatClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e7891e-27e8-4781-87cf-91a47868cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"what was descartes most notible work. Then find one glaring flaw in his logic?'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6b9e82-520a-4b71-8086-f4d75f7f87e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "René Descartes (1596-1650) is widely regarded as the father of modern Western philosophy. One of his most notable works is:\n",
      "\n",
      "**\"Meditations on First Philosophy\" (1641)**\n",
      "\n",
      "In this work, Descartes presents a philosophical method of systematic doubt, where he questions everything, including his own existence, in an attempt to find a foundation for knowledge that is certain and indubitable. The Meditations is a six-part work, each of which explores a different aspect of Descartes' thoughts on metaphysics, epistemology, and the nature of reality.\n",
      "\n",
      "Now, regarding a glaring flaw in his logic, I'd like to highlight:\n",
      "\n",
      "**The Cogito Flaw**\n",
      "\n",
      "Descartes' most famous conclusion from the Meditations is the one known as the Cogito (Latin for \"I think\"). In the Second Meditation, he famously writes: \"I think, therefore I am\" (Cogito, ergo sum). He argues that, even if he doubts everything else, including the existence of his own body, the act of doubting itself proves his own existence as a thinking being.\n",
      "\n",
      "However, this conclusion is questionable because:\n",
      "\n",
      "**Descartes relies on the very thing he's trying to prove**\n",
      "\n",
      "The Cogito itself relies on the assumption that thinking (or doubting) is occurring. But how does Descartes know that he's thinking or doubting? Doesn't this knowledge come from the sensory experiences that Descartes himself is questioning? If we can't trust our senses, then how can we be certain that we're thinking at all?\n",
      "\n",
      "Put simply, the Cogito assumes that Descartes is thinking just because he thinks he's thinking. This is a classic case of **epistemic circularity**, where the conclusion (I am thinking) relies on the same assumptions as the premise (I think), without adding any new information to confirm certainty.\n",
      "\n",
      "In other words, Descartes' elegant conclusion (\"I am thinking, therefore I am\") relies on the very foundation he's trying to establish, creating an unfalsifiable and potentially circular argument.\n",
      "\n",
      "So, while the Cogito remains one of the most iconic conclusions in the history of philosophy, its underlying flaw highlights the ongoing challenges of epistemological inquiry and the pursuit of certainty in a complex world.\n"
     ]
    }
   ],
   "source": [
    "# For streaming responses (will print as it receives chunks):\n",
    "response = chat_client.chat(message, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d87608-c072-4720-acce-f80407e20e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "message2 = \"can you make connection to this meditatino and the turning test?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844cd929-ff06-44f0-8ec6-072b62180489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A great connection to make!\n",
      "\n",
      "The Meditations on First Philosophy (1641) by René Descartes, where he famously concludes with the Cogito (I think, therefore I am), bears a fascinating relation to the **Turing Test** (1950).\n",
      "\n",
      "**What is the Turing Test?**\n",
      "\n",
      "In 1950, Alan Turing proposed a thought experiment to determine whether a machine (computer) could be said to think like a human. The Turing Test involves a human evaluator who engages in natural language conversations with both a human and a machine, without knowing which is which. If the evaluator cannot reliably distinguish the human from the machine, the machine is said to have passed the Turing Test.\n",
      "\n",
      "**Connection to Descartes' Meditations**\n",
      "\n",
      "Now, let's connect the Meditations to the Turing Test:\n",
      "\n",
      "**The Cogito as a precursor to the Turing Test**\n",
      "\n",
      "In the Meditations, Descartes attempts to establish a foundation for knowledge that is certain and indubitable. He uses the Cogito to prove his own existence, relying on the assumption that thinking is a fundamental, uncontested fact. This idea of a being (or machine) that thinks and reasoning is applied to a program is essentially an anticipation of the Turing Test.\n",
      "\n",
      "**Similarities between the ideal user (Turing) and the ego (Descartes)**\n",
      "\n",
      "1. **Objective understanding**: Both the ideal user in the Turing Test and Descartes' ego are detached observers, passively understanding interactions with others or themselves.\n",
      "2. **Reasoning**: Both rely on reasoning to understand the context and form conclusions.\n",
      "3. **Self-definition**: Both aim to establish a sense of identity and understanding of their (or the program's) existence.\n",
      "\n",
      "**What's the same, what's different?**\n",
      "\n",
      "While the Meditations and the Turing Test share some similarities, there are also significant differences:\n",
      "\n",
      "* **Purpose**: Descartes aimed to prove his and others' existence through an internal experience (Cogito), whereas the Turing Test is a means to test a machine's ability to mimic human thought processes.\n",
      "* **Testing context**: Descartes' Meditations dealt with the inner workings of his mind, while the Turing Test concerns interactions with an external entity (machine or program).\n",
      "\n",
      "**The limits of self-awareness**\n",
      "\n",
      "Both the Cogito and the Turing Test explore the limits of self-awareness, yet they offer insights into different areas of inquiry:\n",
      "\n",
      "* **Presumpiton of consciousness**: Descartes exploits the assumption that thinking is a self-evident fact, making the existence of the thinker a non-negotiable stance.\n",
      "* **Simulation and communication**: The Turing Test advances by succeeding in simulating, or at least engaging with, conversation.\n",
      "\n",
      "However, when it comes to truly measuring **self-awareness**, Descartes' conclusions are dependent on the primacy of thinking (Cogito) to confirm his own existence. This contrasts with the Turing Test, which remains debatable as to whether it can prove artificial intelligence (AI) has true self-awareness.\n",
      "\n",
      "The intersection of these philosophical ideas highlights the challenging relationship between our self-perceived understanding and external recognition.\n",
      "\n",
      "Fascinating, isn't it?\n"
     ]
    }
   ],
   "source": [
    "# For streaming responses (will print as it receives chunks):\n",
    "response = chat_client.chat(message2, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a116c314-bdb2-47e5-bbda-a863a35130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For streaming responses:\n",
    "# for response in chat_client.chat(message):\n",
    "#     print(response, end=\"\\r\")\n",
    "# print()  # New line after response is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9563304-d38f-45b8-9477-4b89cd9f0d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
