{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295cacb5-b676-4925-8677-e2a177047fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must run on => Python 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715f17e3-fef9-461e-b4a2-d0af5631b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import httpx\n",
    "import json\n",
    "from typing import List, Dict, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b174c3a1-2b3e-4c85-aa44-3ff165c59c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'https://caii-prod-validation.eng-ml-l.vnu8-sqze.cloudera.site/namespaces/serving-default/endpoints/deepseek-r1-distill-8b/openai/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc29c02-b05e-4e80-8b3e-afd17b0dcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Llama-8B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa52d379-0f54-4c23-b6d5-091c1b31116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatClient:\n",
    "    def __init__(self):\n",
    "          \n",
    "        # Set up HTTP client\n",
    "        if \"CUSTOM_CA_STORE\" not in os.environ:\n",
    "            http_client = httpx.Client()\n",
    "        else:\n",
    "            http_client = httpx.Client(verify=os.environ[\"CUSTOM_CA_STORE\"])\n",
    "            \n",
    "        # Load API key\n",
    "        OPENAI_API_KEY = json.load(open(\"/tmp/jwt\"))[\"access_token\"]\n",
    "        \n",
    "        # Initialize OpenAI client\n",
    "        self.client = OpenAI(\n",
    "            base_url = model_url,\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            http_client=http_client,\n",
    "        )\n",
    "        \n",
    "        self.conversation_history: List[Dict[str, str]] = []\n",
    "        \n",
    "    def chat(self, message: str, stream: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Send a message to the chat model and get the response.\n",
    "        \n",
    "        Args:\n",
    "            message: The message to send to the model\n",
    "            stream: Whether to stream the response or return it all at once\n",
    "            \n",
    "        Returns:\n",
    "            The complete response as a string\n",
    "        \"\"\"\n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        if stream:\n",
    "            partial_message = \"\"\n",
    "            response = self.client.chat.completions.create(\n",
    "                model= model_name,\n",
    "                messages=self.conversation_history,\n",
    "                stream=True,\n",
    "            )\n",
    "            \n",
    "            for chunk in response:\n",
    "                if chunk.choices[0].delta.content is not None:\n",
    "                    content = chunk.choices[0].delta.content\n",
    "                    partial_message += content\n",
    "                    print(content, end='', flush=True)\n",
    "            \n",
    "            print()  # New line after response is complete\n",
    "            # Add complete response to history\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": partial_message})\n",
    "            return partial_message\n",
    "            \n",
    "        else:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=self.conversation_history,\n",
    "                stream=False,\n",
    "            )\n",
    "            complete_response = response.choices[0].message.content\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": complete_response})\n",
    "            return complete_response\n",
    "    \n",
    "    def get_history(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Get the conversation history.\"\"\"\n",
    "        return self.conversation_history\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        self.conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6603b52-e28c-4ea1-ac41-d41f11a9f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chat client\n",
    "chat_client = ChatClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e7891e-27e8-4781-87cf-91a47868cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "message =\"\"\"\n",
    "\"In a room of 30 people, everyone shakes hands exactly once with everyone else. How many total handshakes occur? Walk me through your reasoning step by step.\"\"\"\n",
    "# \"\"\"You are a JSON extraction system. Extract customer information and return ONLY a JSON object.\n",
    "\n",
    "# Format must be exactly:\n",
    "# {\n",
    "#     \"account_id\": \"four digit account ID or empty string\",\n",
    "#     \"name\": \"full name or empty string\"\n",
    "# }\n",
    "# DO NOT add any extra text or conversation.\n",
    "\n",
    "# Example:\n",
    "# Input: \"Hi, my name is John Smith and my account number is 1234\"\n",
    "# Output: {\n",
    "#     \"account_id\": \"1234\",\n",
    "#     \"name\": \"John Smith\"\n",
    "# }\n",
    "\n",
    "# Input: \"Hello, I'm Mary Jones\"\n",
    "# Output: {\n",
    "#     \"account_id\": \"\",\n",
    "#     \"name\": \"Mary Jones\"\n",
    "# }\n",
    "\n",
    "# Here is the conversation to analyze: 'Hello my name is Max Fisher and my account ID is 1004.'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6b9e82-520a-4b71-8086-f4d75f7f87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For streaming responses (will print as it receives chunks):\n",
    "response = chat_client.chat(message, stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "282cf2c7-ba2f-4358-aaad-7a67aec9d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nFirst, I need to understand that every person in the room will shake hands with every other person exactly once.\\n\\nThere are 30 people in total.\\n\\nNext, I'll determine how many handshakes each person will initiate. Since each person shakes hands with 29 others, that means 29 handshakes per person.\\n\\nTo find the total number of unique handshakes, I need to consider that each handshake is counted twice when considering all individual handshakes. Therefore, I'll use the formula for combinations, specifically the number of ways to choose 2 people out of 30.\\n\\nCalculating this gives me 30 multiplied by 29 divided by 2, which equals 435.\\n\\nSo, there are a total of 435 unique handshakes in the room.\\n</think>\\n\\nLet's determine the total number of handshakes that occur when each of the 30 people in the room shakes hands with every other person exactly once. Here's a step-by-step breakdown of the reasoning:\\n\\n### Step 1: Understand the Problem\\n- **Total number of people in the room (n):** 30\\n- **Each person shakes hands with every other person exactly once.**\\n\\n### Step 2: Calculate Handshakes per Person\\n- **Number of handshakes each person makes:** Since each person shakes hands with every other person, each person will shake hands with \\\\( n - 1 \\\\) others.\\n  \\\\[\\n  \\\\text{Handshakes per person} = 30 - 1 = 29\\n  \\\\]\\n\\n### Step 3: Calculate Total Handshakes\\n- **Total handshakes if each handshake is counted separately:** \\n  \\\\[\\n  30 \\\\times 29 = 870\\n  \\\\]\\n  \\n- However, this counts each handshake twice because when Person A shakes hands with Person B, it's counted once for A and once for B. To find the actual number of unique handshakes, divide by 2:\\n  \\\\[\\n  \\\\frac{870}{2} = 435\\n  \\\\]\\n\\n### Final Answer\\n\\\\[\\n\\\\boxed{435}\\n\\\\]\\n\\nThis method uses the concept of **combinations** (specifically, the combination formula \\\\( \\\\binom{n}{2} \\\\)) to determine the number of unique handshakes possible among \\\\( n \\\\) people.\\n\\n\\\\[\\n\\\\text{Total Handshakes} = \\\\binom{30}{2} = \\\\frac{30 \\\\times 29}{2} = 435\\n\\\\]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8d87608-c072-4720-acce-f80407e20e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "message2 = \" what do you mean by : allows computer systems to automatically learn and improve from experience without being explicitly programmed? can you give me an example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "844cd929-ff06-44f0-8ec6-072b62180489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I say \"allows computer systems to automatically learn and improve from experience without being explicitly programmed,\" I mean that machine learning algorithms are designed to find patterns and make predictions based on data, rather than being explicitly coded to perform a specific task.\n",
      "\n",
      "For example, let's say we have a large dataset of emails, and we want to create a system that can automatically classify each email as spam or not spam. Instead of manually programming a set of rules to determine whether an email is spam or not based on features like the presence of certain keywords or the email address of the sender, we can use a machine learning algorithm to learn the patterns that distinguish spam emails from non-spam emails from the data.\n",
      "\n",
      "The algorithm would analyze the dataset and come up with a mathematical model that can classify new emails as spam or not spam based on the patterns it has learned. As the algorithm is exposed to more data over time, it can continuously improve its performance and make more accurate predictions.\n",
      "\n",
      "This is an example of supervised learning, as we are training the algorithm on labeled data where the correct output (spam or not spam) is provided for each input (email). The algorithm learns the patterns that distinguish these classes by minimizing the difference between its predicted outputs and the true outputs, which is known as training error.\n",
      "\n",
      "In this example, we didn't have to explicitly program the algorithm with a set of rules for detecting spam emails, but instead, we let it learn from the data on its own. This is the essence of automatic learning and improvement from experience without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "# For streaming responses (will print as it receives chunks):\n",
    "response = chat_client.chat(message2, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a116c314-bdb2-47e5-bbda-a863a35130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For streaming responses:\n",
    "# for response in chat_client.chat(message):\n",
    "#     print(response, end=\"\\r\")\n",
    "# print()  # New line after response is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9563304-d38f-45b8-9477-4b89cd9f0d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
