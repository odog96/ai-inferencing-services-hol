{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1031639-fc7b-48fe-abf7-c526b0beff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import httpx\n",
    "from PIL import Image # Import Pillow for image processing\n",
    "import numpy as np # Import numpy for array manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703fd37d-393e-403d-a47f-7f854e77bb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready.\n",
      "\n",
      "Model Metadata:\n",
      "{\n",
      "  \"name\": \"rtcn-dmnq-p6oh-4e8f\",\n",
      "  \"versions\": [\n",
      "    \"1\"\n",
      "  ],\n",
      "  \"platform\": \"onnxruntime_onnx\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"input\",\n",
      "      \"datatype\": \"FP32\",\n",
      "      \"shape\": [\n",
      "        -1,\n",
      "        1,\n",
      "        224,\n",
      "        224\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"name\": \"output\",\n",
      "      \"datatype\": \"FP32\",\n",
      "      \"shape\": [\n",
      "        -1,\n",
      "        2\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Detected Input Name: input\n",
      "Detected Input Shape: [-1, 1, 224, 224]\n",
      "Detected Input Datatype: FP32\n",
      "Target image size for model: (224, 224)\n",
      "image path is /home/cdsw/person1946_bacteria_4874.jpeg\n",
      "Preprocessed image array shape: (1, 1, 224, 224)\n",
      "Image data flattened. Total elements: 50176\n",
      "\n",
      "Making inference request...\n",
      "\n",
      "Inference Response:\n",
      "{\n",
      "  \"model_name\": \"rtcn-dmnq-p6oh-4e8f\",\n",
      "  \"model_version\": \"1\",\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"name\": \"output\",\n",
      "      \"shape\": [\n",
      "        1,\n",
      "        2\n",
      "      ],\n",
      "      \"datatype\": \"FP32\",\n",
      "      \"data\": [\n",
      "        -8.839442253112793,\n",
      "        10.951461791992188\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have these installed:\n",
    "# pip install open-inference-openapi httpx Pillow numpy\n",
    "\n",
    "from open_inference.openapi.client import OpenInferenceClient, InferenceRequest\n",
    "\n",
    "#If running from workbench use /tmp/jwt. Otherwise provide your CDP_TOKEN\n",
    "#Make sure to replace \"/tmp/jwt\" with the actual path to your JWT file if different\n",
    "try:\n",
    "    API_KEY = json.load(open(\"/tmp/jwt\"))[\"access_token\"]\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: /tmp/jwt not found. Please ensure you have a valid CDP_TOKEN or JWT file.\")\n",
    "    # You might want to prompt the user for API_KEY here or exit\n",
    "#API_KEY = \"eyJraWQiOiIzYzhlNzA3OTEyZmI0NTA1ODE3NzE3YzMyOTU4MmQwMTFjYjlmNTAwIiwidHlwIjoiSldUIiwiYWxnIjoiUlMyNTYifQ.eyJzdWIiOiJvemFyYXRlIiwiYXVkIjoiaHR0cHM6Ly9kZS55bGN1LWF0bWkuY2xvdWRlcmEuc2l0ZSIsImlzcyI6Imh0dHBzOi8vY29uc29sZWF1dGguY2RwLmNsb3VkZXJhLmNvbS84YTFlMTVjZC0wNGMyLTQ4YWEtOGYzNS1iNGE4YzExOTk3ZDMiLCJncm91cHMiOiJjZHBfZGVtb3Nfd29ya2Vyc193dyBjZHBfZGVtby1hd3MtcHJpbSBfY19kZl9kZXZlbG9wXzkxMTQ2M2MgX2NfbWxfYWRtaW5zXzViNTQ3ZDI2IF9jX21sX2J1c2luZXNzX3VzZXJzXzc3ODkxZjJlIF9jX2RmX3ZpZXdfNmY1OWU5ZjMgX2NfZGZfYWRtaW5pc3Rlcl85MTE0NjNjIF9jX21sX3VzZXJzXzc3ODkxZjJlIF9jX2RmX3ZpZXdfOTExNDYzYyBfY19tbF9idXNpbmVzc191c2Vyc182ZWUwZGI5MSBfY19kZl9wdWJsaXNoXzkxMTQ2M2MgX2NfZGZfdmlld185MTE0NjNjMCBfY19lbnZfYXNzaWduZWVzXzkxMTQ2M2MgX2NfcmFuZ2VyX2FkbWluc185MDZiMGJhIF9jX21sX3VzZXJzXzZmNTllOWYzIF9jX21sX3VzZXJzXzRkODNhZDdmIF9jX2Vudl9hc3NpZ25lZXNfOTA2YjBiYSBfY19kZl9kZXZlbG9wXzZmNTllOWYzIF9jX2RmX2FkbWluaXN0ZXJfNmY1OWU5ZjMgX2NfZGZfcHVibGlzaF82ZjU5ZTlmMyBfY19tbF91c2Vyc182ZWUwZGI5MSBfY19tbF9idXNpbmVzc191c2Vyc182ZjU5ZTlmMyBfY19tbF9idXNpbmVzc191c2Vyc185MTE0NjNjIF9jX21sX2FkbWluc183Nzg5MWYyZSBfY19lbnZfYXNzaWduZWVzXzZmNTllOWYzIF9jX3Jhbmdlcl9hZG1pbnNfNmY1OWU5ZjMgX2NfcmFuZ2VyX2FkbWluc185MTE0NjNjIF9jX2RlX3VzZXJzXzkxMTQ2M2MgX2NfbWxfdXNlcnNfOTExNDYzYyBfY19kZl9wcm9qZWN0X21lbWJlcl80MGRmZTU2OCBfY19kZl92aWV3XzZmNTllOWYzMCBfY19kZl9wcm9qZWN0X21lbWJlcl81NzVmODRmNyBfY19kZV91c2Vyc182ZjU5ZTlmMyIsImV4cCI6MTc1MzIxNzU0MCwidHlwZSI6InVzZXIiLCJnaXZlbl9uYW1lIjoiT2xpdmVyIiwiaWF0IjoxNzUzMjEzOTQwLCJmYW1pbHlfbmFtZSI6IlphcmF0ZSIsImVtYWlsIjoib3phcmF0ZUBjbG91ZGVyYS5jb20ifQ.vw8N3uaFA-16BRd1yA9cOHteHKIIiHq2wA1j90iMZzcv0oq_QdhIIk_KLW-Yq0JFZr9kBgCD9cZmR3mLh0aKLx9o0sqapE0kvStBqLmvzoAQDEGSvo5nD0xxkOePelnxFsc6yVRxLjctWxjhyzapGolCZ8Yv_FR0n3y-Tl_fIin1l0tT-dUz8y11eF_jKBjmORwaCPxgakzk8sNTnrrNsWKyyxEkUb07ivPfW4jztJwoH1nZxmvxueXrxah5ZGVil_mF9DCm3ry3Erd-RF9VHjFW4vmTn4c7kR4JAnw7eHpf2SphiwBmCR59yLihzwwsGZIp-9110CLnRCOfudCIlQ\" # Fallback to environment variable or placeholder\n",
    "\n",
    "BASE_URL = 'https://ml-2dad9e26-62f.go01-dem.ylcu-atmi.cloudera.site/namespaces/serving-default/endpoints/pneomonia-classifier'\n",
    "MODEL_NAME = 'rtcn-dmnq-p6oh-4e8f'\n",
    "headers = {\n",
    "\t'Authorization': 'Bearer ' + API_KEY,\n",
    "\t'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "httpx_client = httpx.Client(headers=headers)\n",
    "client = OpenInferenceClient(base_url=BASE_URL, httpx_client=httpx_client)\n",
    "\n",
    "# Check that the server is live, and it has the model loaded\n",
    "try:\n",
    "    client.check_server_readiness()\n",
    "    print(\"Server is ready.\")\n",
    "    metadata = client.read_model_metadata(MODEL_NAME)\n",
    "    metadata_str = json.dumps(json.loads(metadata.json()), indent=2)\n",
    "    print(\"\\nModel Metadata:\")\n",
    "    print(metadata_str)\n",
    "\n",
    "    # --- Extract input details from metadata ---\n",
    "    # Assuming the model has at least one input and it's an image\n",
    "    model_inputs_meta = json.loads(metadata.json()).get(\"inputs\", [])\n",
    "    if not model_inputs_meta:\n",
    "        raise ValueError(\"Model metadata does not contain input information.\")\n",
    "\n",
    "    # For simplicity, we'll assume the first input in the metadata is the one we need.\n",
    "    # In a real application, you might need to iterate or check names if there are multiple inputs.\n",
    "    input_name = model_inputs_meta[0][\"name\"]\n",
    "    input_shape = model_inputs_meta[0][\"shape\"]\n",
    "    input_datatype = model_inputs_meta[0][\"datatype\"]\n",
    "\n",
    "    print(f\"\\nDetected Input Name: {input_name}\")\n",
    "    print(f\"Detected Input Shape: {input_shape}\")\n",
    "    print(f\"Detected Input Datatype: {input_datatype}\")\n",
    "\n",
    "    # --- Image Loading and Preprocessing ---\n",
    "    # Define the path to your local JPEG image\n",
    "    # IMPORTANT: Replace 'path/to/your/image.jpeg' with the actual path to your image file\n",
    "    IMAGE_PATH = \"/home/cdsw/person1946_bacteria_4874.jpeg\" # e.g., 'patient_xray.jpeg'\n",
    "\n",
    "    # Determine the target image size from the model's input shape\n",
    "    # The model expects [-1, 1, 224, 224] -> [BATCH, CHANNEL, HEIGHT, WIDTH]\n",
    "    # Pillow's resize expects (width, height)\n",
    "    if len(input_shape) >= 3: # Ensure there are enough dimensions for height and width\n",
    "        target_height = input_shape[-1] # Last dimension is width\n",
    "        target_width = input_shape[-2] # Second to last dimension is height\n",
    "        target_size = (target_height, target_width) # Pillow expects (width, height)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected input shape for image: {input_shape}. Cannot determine resize dimensions.\")\n",
    "\n",
    "    print(f\"Target image size for model: {target_size}\")\n",
    "\n",
    "    try:\n",
    "        img = Image.open(IMAGE_PATH)\n",
    "        img = img.resize(target_size) # Resize image to model's expected dimensions (224x224)\n",
    "        \n",
    "        # Convert to grayscale ('L' for Luminance) as the model expects 1 channel\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "\n",
    "        # Convert image to a numpy array\n",
    "        img_array = np.asarray(img) # Shape will be (HEIGHT, WIDTH) for grayscale\n",
    "\n",
    "        # Normalize pixel values if the model expects FP32 in a certain range (e.g., 0-1)\n",
    "        # This is a common step for deep learning models. Adjust as per your model's training.\n",
    "        if input_datatype == \"FP32\":\n",
    "            img_array = img_array / 255.0 # Normalize to 0-1 range for FP32\n",
    "\n",
    "        # Add batch dimension and channel dimension, then transpose to [BATCH, CHANNEL, HEIGHT, WIDTH]\n",
    "        # Current img_array shape for grayscale is (HEIGHT, WIDTH)\n",
    "        # Add channel dimension (1) at axis 0: (1, HEIGHT, WIDTH)\n",
    "        # Add batch dimension (1) at axis 0: (1, 1, HEIGHT, WIDTH)\n",
    "        img_array = img_array[np.newaxis, np.newaxis, :, :]\n",
    "\n",
    "        # Verify the final shape before flattening\n",
    "        print(f\"Preprocessed image array shape: {img_array.shape}\")\n",
    "\n",
    "        # Flatten the numpy array to a 1D list\n",
    "        image_data_flat = img_array.flatten().tolist()\n",
    "        print(f\"Image data flattened. Total elements: {len(image_data_flat)}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {IMAGE_PATH}. Please check the path.\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Make an inference request\n",
    "    print(\"\\nMaking inference request...\")\n",
    "    pred = client.model_infer(\n",
    "        MODEL_NAME,\n",
    "        request=InferenceRequest(\n",
    "            inputs=[\n",
    "                {\n",
    "                    \"name\": input_name,\n",
    "                    \"shape\": list(img_array.shape), # Use the actual shape of the prepared numpy array (e.g., [1, 1, 224, 224])\n",
    "                    \"datatype\": input_datatype,\n",
    "                    \"data\": image_data_flat\n",
    "                }\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    json_resp_str = json.dumps(json.loads(pred.json()), indent=2)\n",
    "    print(\"\\nInference Response:\")\n",
    "    print(json_resp_str)\n",
    "\n",
    "except httpx.HTTPStatusError as e:\n",
    "    print(f\"HTTP Error: {e.response.status_code} - {e.response.text}\")\n",
    "    print(\"Please check your BASE_URL, MODEL_NAME, and API_KEY.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910ac27-9865-4a54-bda6-7f27dd97d4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37cfce-663e-40b6-8ab4-51f8a562df07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
